{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b08ea5",
   "metadata": {},
   "source": [
    "## Notes \n",
    "- For the moment the model is only tokenized with the `text_body` and not with the `text_title`\n",
    "- The evalutation training metric is the `accuracy`. Is it the best metric for an ordered variable ? (classify 4 instead of 5 is less important than classify 1 instead of 5)\n",
    "- for the moment we do not monitor the evaluation metric during fine-tuning. What does it mean ? Is it useful ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91a9d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA TITAN Xp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40823a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fr_name = 'camembert-base'\n",
    "model_en_name = 'roberta-base'\n",
    "model_translation = {}\n",
    "model_translation['fr_en'] = 'Helsinki-NLP/opus-mt-fr-en'\n",
    "model_translation['en_fr'] = 'Helsinki-NLP/opus-mt-en-fr'\n",
    "dataset_name = 'amazon_reviews_multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aeb57a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-abef70f0f0f656cb.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-79c67e48d5206038.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-faeec778108fe3de.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-41232663b589bd61.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-a0643c95f4c42f55.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-e410a814911a5d0f.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-a2ae2a6214ac6047.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-618a1b0d86ecd75f.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-c4ac636510305d82.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-c1734b10644108e1.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-28f888a3174dbd90.arrow\n",
      "Loading cached processed dataset at /home/desponds/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-76f8d8375117bd8b.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "def stars_into_labels(example):\n",
    "    # Change the range of stars [1-5] to labels [0-4]\n",
    "    example['stars'] = example['stars']-1\n",
    "    return example\n",
    "\n",
    "def get_dataset_language(full_dataset, language) :\n",
    "    dataset_out = {}\n",
    "    for split in full_dataset : \n",
    "        #Take only the language of interest\n",
    "        dataset_out[split] = dataset[split].filter(lambda exemple : exemple['language'] == language)\n",
    "        #Remove useless columns\n",
    "        dataset_out[split] = dataset_out[split].remove_columns([\"review_id\",\"product_id\", \"reviewer_id\",\n",
    "        \"review_title\",\"language\",\"product_category\"])\n",
    "        #Change the range of the labels and rename the column for the training\n",
    "        dataset_out[split] = dataset_out[split].rename_column(\"review_body\", \"text\")\n",
    "        dataset_out[split] = dataset_out[split].map(stars_into_labels)\n",
    "        dataset_out[split] = dataset_out[split].rename_column(\"stars\", \"label\")\n",
    "    return DatasetDict(dataset_out)\n",
    "\n",
    "#Prprocess the datasets\n",
    "dataset_fr = get_dataset_language(dataset, 'fr')\n",
    "dataset_en = get_dataset_language(dataset, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f262d36a",
   "metadata": {},
   "source": [
    "## 2.1 Fine-tune French Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbd6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Take the tokenizers of the respective models\n",
    "tokenizer = {}\n",
    "tokenizer['fr'] = AutoTokenizer.from_pretrained(model_fr_name)\n",
    "tokenizer['en'] = AutoTokenizer.from_pretrained(model_en_name)\n",
    "\n",
    "def tokenize_function(examples, language):\n",
    "    return tokenizer[language](examples[\"text\"], \n",
    "                     padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize all the data\n",
    "for split in dataset_fr :\n",
    "    dataset_fr[split] = dataset_fr[split].map(lambda examples : tokenize_function(examples,'fr'), batched=True)\n",
    "    dataset_en[split] = dataset_en[split].map(lambda examples : tokenize_function(examples,'en'), batched=True)\n",
    "\n",
    "\n",
    "#Take only a small part of the dataset for testing\n",
    "small_fr_dataset = {}\n",
    "for split in dataset_fr :\n",
    "    small_fr_dataset[split] =  dataset_fr[split].shuffle(seed=42).select(range(50))\n",
    "small_fr_dataset = DatasetDict(small_fr_dataset)\n",
    "\n",
    "# Load the two pretrained models\n",
    "model = {}\n",
    "model['fr'] = AutoModelForSequenceClassification.from_pretrained(model_fr_name, num_labels=5)\n",
    "model['en'] = AutoModelForSequenceClassification.from_pretrained(model_en_name, num_labels=5)\n",
    "\n",
    "# Set the training arguments for both trainer\n",
    "training_args = {}\n",
    "training_args['fr'] = TrainingArguments(output_dir=\"test_trainer_fr\", evaluation_strategy=\"epoch\")\n",
    "training_args['en'] = TrainingArguments(output_dir=\"test_trainer_en\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "\n",
    "# Set the metric to accuracy for the training\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = {}\n",
    "trainer['fr'] = Trainer(\n",
    "    model=model['fr'],\n",
    "    args=training_args['fr'],\n",
    "    train_dataset= dataset_fr['train'],\n",
    "    eval_dataset= dataset_fr['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer['en'] = Trainer(\n",
    "    model=model['en'],\n",
    "    args=training_args['en'],\n",
    "    train_dataset= dataset_en['train'],\n",
    "    eval_dataset= dataset_en['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer['fr'].train('/data/desponds/data/Classification/trainer_fr/checkpoint-37500')\n",
    "trainer['en'].train('/data/desponds/data/Classification/trainer_en/checkpoint-37500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0bb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args['fr'].device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564f14d",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "SOhelp : https://stackoverflow.com/questions/70043467/how-to-run-huggingface-helsinki-nlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d7dd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading file source.spm from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/source.spm\n",
      "loading file target.spm from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/target.spm\n",
      "loading file vocab.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/vocab.json\n",
      "loading file target_vocab.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/tokenizer_config.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading configuration file config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "/data/desponds/anaconda3/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "loading configuration file config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-fr-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "/data/desponds/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My name is Mathieu and I live in Lausanne.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing how to translate\n",
    "\n",
    "# First way of translation \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_trad = AutoTokenizer.from_pretrained(model_translation['fr_en'] )\n",
    "model_trad = AutoModelForSeq2SeqLM.from_pretrained(model_translation['fr_en'] )\n",
    "\n",
    "inp = \"Je m'appelle Mathieu et je vis Ã  Lausanne\"\n",
    "input_ids = tokenizer_trad(inp, return_tensors=\"pt\").input_ids\n",
    "outputs = model_trad.generate(input_ids=input_ids, num_return_sequences=1)\n",
    "print(tokenizer_trad.batch_decode(outputs, skip_special_tokens=True)[0])\n",
    "\n",
    "# Second way of translation with more abstraction\n",
    "from transformers import pipeline\n",
    "translator = {}\n",
    "translator['fr_en'] = pipeline(\"translation\", model='Helsinki-NLP/opus-mt-fr-en')\n",
    "print(translator['fr_en'](\"Ce cours est produit par Hugging Face.\")[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24f4bff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading file source.spm from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/source.spm\n",
      "loading file target.spm from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/target.spm\n",
      "loading file vocab.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/vocab.json\n",
      "loading file target_vocab.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/tokenizer_config.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading configuration file config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"decoder_vocab_size\": 59514,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59514\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-fr-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/desponds/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-fr-en/snapshots/49463f1706007cb314a942296b77a6483e6f6953/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59513\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59513,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59513,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer_trad_fr_en = AutoTokenizer.from_pretrained(model_translation['fr_en'] )\n",
    "model_trad_fr_en = AutoModelForSeq2SeqLM.from_pretrained(model_translation['fr_en'] )\n",
    "\n",
    "def translate_fr_en(example):\n",
    "    inp = example['text']\n",
    "    input_ids = tokenizer_trad_fr_en(inp, \n",
    "                                     return_tensors=\"pt\",\n",
    "                                     padding=\"max_length\", \n",
    "                                     truncation=True).input_ids\n",
    "    outputs = model_trad_fr_en.generate(input_ids=input_ids, num_return_sequences=1)\n",
    "    example[\"text\"] = tokenizer_trad_fr_en.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return example\n",
    "\n",
    "# Translate the test split of the french dataset\n",
    "translated_fr_en = dataset_fr['test'].map(translate_fr_en)\n",
    "\n",
    "#Recompute the tokens of the translated version\n",
    "translated_fr_en.remove_columns(['input_ids', 'attention_mask'])\n",
    "translated_fr_en = translated_fr_en.map(lambda examples : tokenize_function(examples,'en'), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf9ccb",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0018745f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `CamembertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `CamembertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "/data/desponds/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.8188376 ,  1.3251189 , -1.0401316 , -2.6615825 , -2.1623106 ],\n",
       "       [ 4.653632  ,  1.5906588 , -0.73805064, -2.70451   , -2.4790804 ],\n",
       "       [ 4.6040254 ,  0.9419153 , -0.99038637, -2.3694022 , -1.9822422 ],\n",
       "       ...,\n",
       "       [-3.5564382 , -2.8816404 ,  0.2015841 ,  2.8081903 ,  2.9350033 ],\n",
       "       [-2.1337707 , -3.0059257 , -1.5882653 ,  1.4551748 ,  4.6391654 ],\n",
       "       [-3.3857815 , -2.827093  ,  0.06521205,  2.5770404 ,  3.1005316 ]],\n",
       "      dtype=float32), label_ids=array([0, 0, 0, ..., 4, 4, 4]), metrics={'test_loss': 0.9777808785438538, 'test_accuracy': 0.5972, 'test_runtime': 77.7849, 'test_samples_per_second': 64.28, 'test_steps_per_second': 4.024})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer['fr'].predict(dataset_fr['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3efc406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "/data/desponds/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.7439485 ,  1.2203276 , -0.5132247 , -2.6602557 , -2.8391514 ],\n",
       "       [ 4.2171583 ,  2.2571788 ,  0.00764171, -2.6744833 , -3.3891168 ],\n",
       "       [ 4.482563  ,  1.9727943 , -0.28513804, -2.7017975 , -3.1886637 ],\n",
       "       ...,\n",
       "       [-3.6019254 , -2.7844594 , -0.5561998 ,  2.6640472 ,  3.7220466 ],\n",
       "       [-3.580228  , -2.8779206 , -1.1100246 ,  2.6448374 ,  4.37079   ],\n",
       "       [-3.6487594 , -2.9328356 , -0.95110667,  2.7271345 ,  4.247052  ]],\n",
       "      dtype=float32), label_ids=array([0, 0, 0, ..., 4, 4, 4]), metrics={'test_loss': 0.9427361488342285, 'test_accuracy': 0.6044, 'test_runtime': 77.3702, 'test_samples_per_second': 64.624, 'test_steps_per_second': 4.045})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer['en'].predict(dataset_en['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b82707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "/data/desponds/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 4.314968  ,  1.1656147 , -0.40019938, -2.3420541 , -2.7511508 ],\n",
       "       [ 4.586199  ,  0.8615197 , -0.4600597 , -2.480549  , -2.6347854 ],\n",
       "       [ 4.063932  ,  0.5198351 , -0.41078267, -2.0535574 , -2.2988946 ],\n",
       "       ...,\n",
       "       [-3.9075608 , -2.305743  ,  0.7384524 ,  3.102282  ,  1.8296533 ],\n",
       "       [-2.533145  , -2.1799974 , -1.9504237 ,  1.2701927 ,  4.6203904 ],\n",
       "       [-3.4184883 , -2.7364452 , -0.8394333 ,  2.434169  ,  3.9835973 ]],\n",
       "      dtype=float32), label_ids=array([0, 0, 0, ..., 4, 4, 4]), metrics={'test_loss': 1.096827745437622, 'test_accuracy': 0.5552, 'test_runtime': 77.6661, 'test_samples_per_second': 64.378, 'test_steps_per_second': 4.03})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer['en'].predict(translated_fr_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f82fe",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28f7656e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>dataset</th>\n",
       "      <th>translated</th>\n",
       "      <th>model</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>Amazon_reviews_fr</td>\n",
       "      <td>no</td>\n",
       "      <td>CamemBERT</td>\n",
       "      <td>0.977781</td>\n",
       "      <td>0.5972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification</td>\n",
       "      <td>Amazon_reviews_en</td>\n",
       "      <td>no</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>0.942736</td>\n",
       "      <td>0.6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classification</td>\n",
       "      <td>Amazon_reviews_fr</td>\n",
       "      <td>yes</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>1.096828</td>\n",
       "      <td>0.5520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             task            dataset translated      model  test_loss  \\\n",
       "0  Classification  Amazon_reviews_fr         no  CamemBERT   0.977781   \n",
       "1  Classification  Amazon_reviews_en         no    Roberta   0.942736   \n",
       "2  Classification  Amazon_reviews_fr        yes    Roberta   1.096828   \n",
       "\n",
       "   test_accuracy  \n",
       "0         0.5972  \n",
       "1         0.6044  \n",
       "2         0.5520  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'task' : ['Classification', 'Classification', 'Classification'],\n",
    "    'dataset' : ['Amazon_reviews_fr', 'Amazon_reviews_en', 'Amazon_reviews_fr'],\n",
    "    'translated' : ['no', 'no', 'yes'],\n",
    "    'model'   : ['CamemBERT', 'Roberta', 'Roberta'],\n",
    "    'test_loss' : [0.9777808785438538, 0.9427361488342285, 1.096827745437622],\n",
    "    'test_accuracy' : [0.5972, 0.6044, 0.552]\n",
    "}\n",
    "results = pd.DataFrame(data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65fc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
