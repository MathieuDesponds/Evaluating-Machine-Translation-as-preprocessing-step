{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1f0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_path = \"/data/desponds/data/Summarization/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb735143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing_summarization\n",
    "datasets, tokenized = preprocessing_summarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783ae89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/data/desponds/data/Summarization/tokenized.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenized, handle)\n",
    "with open('/data/desponds/data/Summarization/datasets.pickle', 'wb') as handle:\n",
    "    pickle.dump(datasets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb90a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lang in ['fr','en'] :\n",
    "    tokenized[lang] = tokenized[lang].map(lambda example: example, remove_columns=['summary', 'text', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47771407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized['fr']['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5db004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/data/desponds/data/Summarization/tokenized.pickle', 'rb') as handle:\n",
    "    tokenized = pickle.load(handle)\n",
    "with open('/data/desponds/data/Summarization/datasets.pickle', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb381a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import get_trainers_summarization\n",
    "trainers = get_trainers_summarization(data_path, tokenized, langs = ['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45097784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainers['fr'].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df83ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers['en'].train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a69cc",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10474d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/data/desponds/data/Summarization/tokenized.pickle', 'rb') as handle:\n",
    "    tokenized = pickle.load(handle)\n",
    "with open('/data/desponds/data/Summarization/datasets.pickle', 'rb') as handle:\n",
    "    datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52190bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation import translate_fr_en_summarization\n",
    "translated_dataset = datasets['fr']['test'].select([5]).map(translate_fr_en_summarization, batched = True)\n",
    "# with open('/data/desponds/data/Summarization/translated_dataset.pickle', 'wb') as handle:\n",
    "#     pickle.dump(translated_dataset, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51db800",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c11635c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': '<extra_id_0>. Vous avez raison. Â»'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"/data/desponds/data/Summarization/trainer_fr/checkpoint-38000\")\n",
    "summarizer(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
