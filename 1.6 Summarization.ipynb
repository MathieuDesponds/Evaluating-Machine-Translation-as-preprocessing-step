{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1f0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_path = \"/data/desponds/data/Summarization/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb735143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing_summarization\n",
    "datasets, tokenized = preprocessing_summarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb381a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import get_trainers_summarization\n",
    "trainers = get_trainers_summarization(data_path, tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45097784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainers['fr'].train()\n",
    "# trainers['en'].train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a69cc",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa7243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_path = \"/data/desponds/data/Summarization/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10474d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/data/desponds/data/Summarization/tokenized.pickle', 'rb') as handle:\n",
    "    tokenized = pickle.load(handle)\n",
    "with open('/data/desponds/data/Summarization/datasets.pickle', 'rb') as handle:\n",
    "    my_datasets = pickle.load(handle)\n",
    "with open(f'/data/desponds/data/Summarization/translated_dataset_tokenized.pickle', 'rb') as handle:\n",
    "    tokenized_fr_en = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dad711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4, len(datasets['fr']['test'])//500 +1):\n",
    "    a = 500 *i\n",
    "    b = min(500*(i+1), len(datasets['fr']['test']))\n",
    "    selection = list(range(a,b))\n",
    "    translated_dataset = datasets['fr']['test'].select(selection).map(translate_fr_en_summarization)\n",
    "    with open(f'/data/desponds/data/Summarization/translated_dataset_{a}_{b}.pickle', 'wb') as handle:\n",
    "        pickle.dump(translated_dataset, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002783f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "all_datasets = [] \n",
    "for i in range(0, len(my_datasets['fr']['test'])//500 +1):\n",
    "    a = 500 *i\n",
    "    b = min(500*(i+1), len(my_datasets['fr']['test']))\n",
    "    with open(f'/data/desponds/data/Summarization/translated_dataset_{a}_{b}.pickle', 'rb') as handle:\n",
    "        all_datasets.append(pickle.load(handle))\n",
    "translated_fr_en = datasets.concatenate_datasets(all_datasets)\n",
    "# translated_fr_en = translated_fr_en.filter(lambda ex : ex['source'] != 'NoTranslation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735880b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_to_remove = translated_fr_en.map(lambda ex, idx : {'idx' : idx} if ex['source'] == 'NoTranslation' else {'idx' : -100}, with_indices = True)\\\n",
    "#                         .filter(lambda ex : ex['idx'] != -100)['idx']\n",
    "indices_to_remove = [2288, 2316, 2333, 3439, 4615, 6045, 6530, 6610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b97a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess_function_summarization\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\")\n",
    "tokenized_fr_en = translated_fr_en.map(lambda examples : preprocess_function_summarization(examples, tokenizer) , batched=True)\n",
    "with open(f'/data/desponds/data/Summarization/translated_dataset_tokenized.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenized_fr_en, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51db800",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94360241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training import get_models_summarization\n",
    "models = get_models_summarization(trainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# results['fr'] = models['fr'].predict(tokenized['fr']['test'])\n",
    "results['fr_baseline'] = models['en'].predict(tokenized['fr']['test'])\n",
    "# results['en'] = models['en'].predict(tokenized['en']['test'])\n",
    "# results['fr_en'] = models['en'].predict(tokenized_fr_en)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation import translate_en_fr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\", cache_dir=\"/data/desponds/.cache\")\n",
    "preds_fr_baseline = []\n",
    "for i, pred in tqdm(enumerate(results['fr_baseline'][0][:])) :\n",
    "    #remove -100\n",
    "    pred = np.where(pred != -100, pred, tokenizer.pad_token_id)\n",
    "    #make it text\n",
    "    pred = tokenizer.decode(pred, skip_special_tokens=True) \n",
    "    preds_fr_baseline.append(translate_en_fr(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca70156",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['fr_baseline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4baeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'/data/desponds/data/Summarization/translated_preds_en_fr.pickle', 'wb') as handle:\n",
    "#     pickle.dump(translated_preds_en_fr, handle)\n",
    "\n",
    "with open(f'/data/desponds/data/Summarization/translated_preds_en_fr.pickle', 'rb') as handle:\n",
    "    translated_preds_en_fr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbaa1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "final_results = {\n",
    "'fr': {'test_loss': 2.488802194595337,'test_rouge1': 0.14,'test_rouge2': 0.0482,'test_rougeL': 0.1284,'test_rougeLsum': 0.1284,'test_gen_len': 18.5642,'test_runtime': 727.3367,'test_samples_per_second': 11.941,'test_steps_per_second': 1.493},\n",
    "'en': {'test_loss': 2.4726946353912354,'test_rouge1': 0.2258,'test_rouge2': 0.0747,'test_rougeL': 0.1972,'test_rougeLsum': 0.1972,'test_gen_len': 18.3344,'test_runtime': 1552.1017,'test_samples_per_second': 12.308,'test_steps_per_second': 1.539},\n",
    "'fr_baseline': {'test_loss': 2.4873387813568115,'test_rouge1': 0.1373,'test_rouge2': 0.0469,'test_rougeL': 0.1259,'test_rougeLsum': 0.1258,'test_gen_len': 18.6025,'test_runtime': 776.9134,'test_samples_per_second': 11.179,'test_steps_per_second': 1.398},\n",
    "'fr_en': {'test_loss': 6.044681549072266,'test_rouge1': 0.0609,'test_rouge2': 0.0152,'test_rougeL': 0.0539,'test_rougeLsum': 0.0539,'test_gen_len': 18.4006,'test_runtime': 657.3901,'test_samples_per_second': 13.199,'test_steps_per_second': 1.65}}\n",
    "pd.DataFrame(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ed1b8",
   "metadata": {},
   "source": [
    "## Putting all together in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1991b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "indices_to_remove = [2288, 2316, 2333, 3439, 4615, 6045, 6530, 6610]\n",
    "df = {}\n",
    "df['fr'] = pd.DataFrame()\n",
    "df['fr']['labels']= [pred for i, pred in enumerate(my_datasets['fr']['test']['target']) if i not in indices_to_remove]\n",
    "df['fr']['preds_fr'] = [pred for i, pred in enumerate(preds_fr) if i not in indices_to_remove]\n",
    "df['fr']['preds_fr_en'] = translated_preds_en_fr\n",
    "df['fr']['preds_fr_baseline'] = [pred for i, pred in enumerate([ p[0] for p in preds_fr_baseline]) if i not in indices_to_remove]\n",
    "\n",
    "df['en'] = pd.DataFrame()\n",
    "df['en']['labels'] = my_datasets['en']['test']['target']\n",
    "df['en']['preds_en'] = preds_en\n",
    "\n",
    "with open(f'/data/desponds/data/Summarization/all_preds.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(f'/data/desponds/data/Summarization/all_preds.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ede3d1",
   "metadata": {},
   "source": [
    "# BERTscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\", cache_dir=\"/data/desponds/.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d783019",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bs = {}\n",
    "results_bs['fr'] = bertscore.compute(predictions=df['fr']['preds_fr'], \n",
    "                            references=df['fr']['labels'], lang=\"fr\", rescale_with_baseline = True)\n",
    "\n",
    "results_bs['fr_en'] = bertscore.compute(predictions=df['fr']['preds_fr_en'], \n",
    "                            references=df['fr']['labels'], lang=\"fr\", rescale_with_baseline = True)\n",
    "\n",
    "results_bs['en'] = bertscore.compute(predictions=df['en']['preds_en'], \n",
    "                            references=df['en']['labels'], lang=\"en\", rescale_with_baseline = True)\n",
    "\n",
    "results_bs['fr_baseline'] = bertscore.compute(predictions=df['fr']['preds_fr_baseline'], \n",
    "                            references=df['fr']['labels'], lang=\"fr\", rescale_with_baseline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/data/desponds/data/Summarization/bert_scores.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_bs, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffdf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/data/desponds/data/Summarization/bert_scores.pickle', 'rb') as handle:\n",
    "    handle.load(results_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cfe320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(results_bs['fr']['f1']), np.mean(results_bs['fr_en']['f1']), np.mean(results_bs['en']['f1']), np.mean(results_bs['fr_baseline']['f1'])\n",
    "#(0.14974178712124486, 0.22737669299686694, 0.27177066745908673, 0.16071509587760247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fr']['BERTscore_fr'] = results_bs['fr']['f1']\n",
    "df['fr']['BERTscore_fr_en'] = results_bs['fr_en']['f1']\n",
    "\n",
    "df['fr']['BERTscore_fr_baseline'] = results_bs['fr_baseline']['f1']\n",
    "\n",
    "df['en']['BERTscore_en'] = results_bs['en']['f1'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce554fb",
   "metadata": {},
   "source": [
    "## Individual ROUGE scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636dc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fr = rouge.compute(predictions=df['fr']['preds_fr'], \n",
    "                            references=df['fr']['labels'], \n",
    "                          use_aggregator =False, \n",
    "                          rouge_types = ['rouge1', 'rouge2', 'rougeL'])\n",
    "result_fr_en = rouge.compute(predictions=df['fr']['preds_fr_en'], \n",
    "                            references=df['fr']['labels'], \n",
    "                          use_aggregator =False, \n",
    "                          rouge_types = ['rouge1', 'rouge2', 'rougeL'])\n",
    "\n",
    "result_fr_baseline = rouge.compute(predictions=df['fr']['preds_fr_baseline'], \n",
    "                            references=df['fr']['labels'], \n",
    "                          use_aggregator =False, \n",
    "                          rouge_types = ['rouge1', 'rouge2', 'rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rouge_type in   ['rouge1', 'rouge2', 'rougeL']:\n",
    "    df['fr'][f'{rouge_type}_fr'] = result_fr[rouge_type]\n",
    "    df['fr'][f'{rouge_type}_fr_en'] = result_fr_en[rouge_type]\n",
    "    df['fr'][f'{rouge_type}_fr_baseline'] = result_fr_baseline[rouge_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fr'][f'rouge1_fr_en'].mean(), df['fr'][f'rouge2_fr_en'].mean(), df['fr'][f'rougeL_fr_en'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcbb351",
   "metadata": {},
   "source": [
    "## Analysis BERTscore and ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check where ther is a big difference in BERTscore\n",
    "df['fr'][np.abs(df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en'])>0.6 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1,3, figsize = (14,4))\n",
    "alpha = 0.3\n",
    "axs = axs.ravel()\n",
    "df['fr']['BERTscore_fr'].plot(kind= 'hist', alpha = alpha, title = \"Distribution of BERTscore\", ax = axs[0], label =\"$metric_{fr}$\", bins = 20)\n",
    "df['fr']['BERTscore_fr_en'].plot(kind= 'hist', alpha = alpha,  ax = axs[0], label =\"$metric_{fr-en}$\", bins = 20)\n",
    "df['fr']['BERTscore_fr_baseline'].plot(kind= 'hist', alpha = alpha,  ax = axs[0], label =\"$metric_{fr-baseline}$\", bins = 20)\n",
    "axs[0].legend()\n",
    "\n",
    "# df['fr']['rouge1_fr'].hist(alpha = 0.5)\n",
    "# df['fr']['rouge1_fr_en'].hist(alpha = 0.5)\n",
    "df['fr']['rouge1_fr'].plot(kind= 'hist', alpha = alpha, title = \"Distribution of ROUGE-1 score\", ax = axs[1], label =\"$metric_{fr}$\", bins = 20)\n",
    "df['fr']['rouge1_fr_en'].plot(kind= 'hist', alpha = alpha,  ax = axs[1], label =\"$metric_{fr-en}$\", bins = 20)\n",
    "df['fr']['rouge1_fr_baseline'].plot(kind= 'hist', alpha = alpha,  ax = axs[1], label =\"$metric_{fr-baseline}$\", bins = 20)\n",
    "axs[1].legend()\n",
    "\n",
    "df['fr']['rouge2_fr'].plot(kind= 'hist', alpha = alpha, title = \"Distribution of ROUGE-2 score\", ax = axs[2], label =\"$metric_{fr}$\", bins = 20)\n",
    "df['fr']['rouge2_fr_en'].plot(kind= 'hist', alpha = alpha,  ax = axs[2], label =\"$metric_{fr-en}$\", bins = 20)\n",
    "df['fr']['rouge2_fr_baseline'].plot(kind= 'hist', alpha = alpha,  ax = axs[2], label =\"$metric_{fr-baseline}$\", bins = 20)\n",
    "axs[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fr'][np.abs(df['fr']['rouge1_fr'] - df['fr']['rouge1_fr_en'])>0.4 ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'rouge1_fr', 'rouge1_fr_en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fr'][np.abs(df['fr']['rouge1_fr'] - df['fr']['rouge1_fr_en'])>0.4 ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'rouge2_fr', 'rouge2_fr_en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5ccdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff_rouge, diff_bert = 0.1,0.2\n",
    "df['fr'][((df['fr']['rouge1_fr'] - df['fr']['rouge1_fr_en']>diff_rouge) \n",
    "          & (df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en']< - diff_bert)& (df['fr']['BERTscore_fr'] >0.2)) \n",
    "         | ((df['fr']['rouge1_fr'] - df['fr']['rouge1_fr_en']< -diff_rouge) \n",
    "          & (df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en'] > diff_bert)& (df['fr']['BERTscore_fr'] >0.2)) ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rouge1_fr', 'rouge1_fr_en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1590929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_rouge, diff_bert = 0.1,0.1\n",
    "df['fr'][((df['fr']['rouge2_fr'] - df['fr']['rouge2_fr_en']>diff_rouge) \n",
    "          & (df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en']< - diff_bert)& df['fr']['BERTscore_fr_en'] >0.4)\n",
    "         | ((df['fr']['rouge2_fr'] - df['fr']['rouge2_fr_en']< -diff_rouge) \n",
    "          & (df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en'] > diff_bert)& df['fr']['BERTscore_fr_en'] >0.4)][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rouge2_fr', 'rouge2_fr_en']].loc[[1302, 8502, 8098, 2284, 100]]\n",
    "#Interesting sample_ids 100 8502 8098 2284 1302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_rouge, diff_bert = 0.1,0.2\n",
    "df['fr'][((df['fr']['rougeL_fr'] - df['fr']['rougeL_fr_en']>diff_rouge) \n",
    "          & (df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en']< - diff_bert)) \n",
    "         | ((df['fr']['rougeL_fr'] - df['fr']['rougeL_fr_en']< -diff_rouge) \n",
    "          & (df['fr']['BERTscore_fr'] - df['fr']['BERTscore_fr_en'] > diff_bert)) ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rougeL_fr', 'rougeL_fr_en']]\n",
    "#Interesting sample_ids 2 100 573 \n",
    "# Downside of ROUGE \n",
    "# ne prend pas en compte les pluriels\n",
    "# Si suite de petit mot comme Quand on doit, va augmenter le score alors que Ã§a ne donne aucune information\n",
    "\n",
    "# Downside of BERTscore\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b74c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fr'][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rouge1_fr', 'rouge1_fr_en']].loc[[1302, 8502, 8098, 2284, 100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33919058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of times berscores and rouge agree\n",
    "len(df['fr'][((df['fr']['rouge1_fr'] > df['fr']['rouge1_fr_en']) & (df['fr']['BERTscore_fr'] > df['fr']['BERTscore_fr_en']))|\n",
    "            ((df['fr']['rouge1_fr'] < df['fr']['rouge1_fr_en']) & (df['fr']['BERTscore_fr'] < df['fr']['BERTscore_fr_en']))\n",
    "            ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rougeL_fr', 'rougeL_fr_en']]), len(df['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of times berscores and rouge agree\n",
    "len(df['fr'][((df['fr']['rouge2_fr'] > df['fr']['rouge2_fr_en']) & (df['fr']['BERTscore_fr'] > df['fr']['BERTscore_fr_en']))|\n",
    "            ((df['fr']['rouge2_fr'] < df['fr']['rouge2_fr_en']) & (df['fr']['BERTscore_fr'] < df['fr']['BERTscore_fr_en']))\n",
    "            ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rougeL_fr', 'rougeL_fr_en']]), len(df['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of times berscores and rouge agree\n",
    "len(df['fr'][((df['fr']['rougeL_fr'] > df['fr']['rougeL_fr_en']) & (df['fr']['BERTscore_fr'] > df['fr']['BERTscore_fr_en']))|\n",
    "            ((df['fr']['rougeL_fr'] < df['fr']['rougeL_fr_en']) & (df['fr']['BERTscore_fr'] < df['fr']['BERTscore_fr_en']))\n",
    "            ][['labels', 'preds_fr', 'preds_fr_en',\n",
    "       'BERTscore_fr', 'BERTscore_fr_en','rougeL_fr', 'rougeL_fr_en']]), len(df['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed55b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fr']['preds_fr_baseline']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1028b5",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94925298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'task' : ['Summarizing','Summarizing', 'Summarizing', 'Summarizing'],\n",
    "    'model'       : ['RoBERTa', 'RoBERTa', 'RoBERTa', 'CamemBERT'],\n",
    "    'train_dataset' : ['GEM/wikilingua en', 'GEM/wikilingua en', 'GEM/wikilingua en', 'GEM/wikilingua fr'],\n",
    "    'nb_sample_train' : [87599, 87599,  87599, 20731],\n",
    "    'test_dataset' : ['GEM/wikilingua en', 'GEM/wikilingua fr', 'GEM/wikilingua fr translated', 'GEM/wikilingua fr',],\n",
    "    'translated' : ['no', 'no', 'yes', 'no'],\n",
    "    'ROUGE 1'    : [1,1,1,1],\n",
    "    'BERTscore'   : [0.27177, 0.16071,  0.22737, 0.14974]\n",
    "}\n",
    "results = pd.DataFrame(data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd0708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
