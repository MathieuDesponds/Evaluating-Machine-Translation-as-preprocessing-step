{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1826780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation import translate_fr_en_paraphrase\n",
    "from transformers import pipeline\n",
    "import pickle\n",
    "data_path = '/data/desponds/data/Paraphrase'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf63771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing_paraphrasing\n",
    "datasets, tokenized = preprocessing_paraphrasing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c396c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training import get_trainers_paraphrasing\n",
    "trainers = get_trainers_paraphrasing(tokenized,data_path,  langs = ['fr', 'en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be85aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training import get_models_paraphrasing\n",
    "models = get_models_paraphrasing(trainers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7964ab",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e59058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation import translate_fr_en_paraphrase\n",
    "from transformers import pipeline\n",
    "import pickle\n",
    "data_path = '/data/desponds/data/Paraphrase'\n",
    "# translator_tc_big = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-fr-en\")\n",
    "translator = pipeline(\"translation\", model=f\"/data/desponds/data/translation_models/model_4_4_epoch_5/checkpoint-15890\")\n",
    "\n",
    "translated_fr_en = datasets['fr']['test'].map(lambda examples : translate_fr_en_paraphrase(examples, translator), batched=True, batch_size = 512)\n",
    "with open(f'{data_path}/translator_t5_small_epoch_5.pickle', 'wb') as handle:\n",
    "        pickle.dump(translated_fr_en, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6131cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation\", model=f\"/data/desponds/data/translation_models/model_t5_small_1_8_epoch_1/checkpoint-795\")\n",
    "\n",
    "translated_fr_en = datasets['fr']['test'].map(lambda examples : translate_fr_en_paraphrase(examples, translator), batched=True, batch_size = 512)\n",
    "with open(f'{data_path}/translator_t5_small_1_8_epoch_1.pickle', 'wb') as handle:\n",
    "        pickle.dump(translated_fr_en, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e9eb2",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc453c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, results = {}, {}\n",
    "# with open(f'{data_path}/translator_t5_base_epoch_3.pickle', 'rb') as handle:\n",
    "#     datasets['translated_t5_base_epoch_3'] = pickle.load(handle)\n",
    "# with open(f'{data_path}/translated_Helsinki-tc-big.pickle', 'rb') as handle:\n",
    "#     datasets['translated_Helsinki-tc-big'] = pickle.load(handle)\n",
    "# with open(f'{data_path}/translated_dataset.pickle', 'rb') as handle:\n",
    "#     datasets['translated_Helsinki'] = pickle.load(handle)\n",
    "# with open(f'{data_path}/translator_t5_small_1_4_epoch_1.pickle', 'rb') as handle:\n",
    "#     datasets['translator_t5_small_1_4_epoch_1'] = pickle.load(handle)\n",
    "# with open(f'{data_path}/translator_t5_small_epoch_5.pickle', 'rb') as handle:\n",
    "#     datasets['translator_t5_small_4_4_epoch_5'] = pickle.load(handle)\n",
    "with open(f'{data_path}/translator_t5_small_1_8_epoch_1.pickle', 'rb') as handle:\n",
    "    datasets['translator_t5_small_1_8_epoch_1'] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc4671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from preprocessing import tokenize_paraphrasing\n",
    "tokenizer = {}\n",
    "tokenizer['en'] = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def preprocess_after_trad(dataset):\n",
    "    dataset = dataset.map(lambda ex : tokenize_paraphrasing(ex, \n",
    "                                                            tokenizer['en'],\n",
    "                                                           with_label = True,\n",
    "                                                           truncation =True))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in datasets :\n",
    "    datasets[name] = preprocess_after_trad(datasets[name])\n",
    "    results[name] = models['en'].predict(datasets[name])\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211478d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trans(example):\n",
    "    example['sentence1'] = example['sentence1']['translation_text']\n",
    "    example['sentence2'] = example['sentence2']['translation_text']\n",
    "    return example\n",
    "\n",
    "for name in datasets:\n",
    "    datasets[name] = datasets[name].map(remove_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d16c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "'t5_small_0' : {'accuracy' : 0.5955,'bleu': 0.7212123764045337},\n",
    "'t5_small_1': {'accuracy' : 0.749, 'bleu':6.0798},\n",
    "'t5_small_2': {'accuracy' : 0.818, 'bleu':18.3099},\n",
    "'t5_small_3': {'accuracy' : 0.8235, 'bleu':20.9125},\n",
    "'t5_base': {'accuracy' : 0.8465, 'bleu':26.0477},\n",
    "'Helsinki': {'accuracy' : 0.911, 'bleu':56.3933},\n",
    "'Helsinki_big': {'accuracy' : 0.913, 'bleu':58.4968}\n",
    "}\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "accuracies = [val['accuracy'] for key, val in final_results.items()]\n",
    "bleus = [val['bleu'] for key, val in final_results.items()]\n",
    "names = [key for key, val in final_results.items()]\n",
    "v_shift = [0,1, -10, 0, 1, -7, -8]\n",
    "v_position = ['bottom','bottom', 'top', 'bottom', 'bottom', 'top','bottom']\n",
    "position = ['bottom','bottom', 'top', 'bottom', 'bottom', 'top','bottom']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(bleus, accuracies)\n",
    "val = 0.002\n",
    "# Add text annotations for names\n",
    "for i, name in enumerate(names):\n",
    "    plt.text(bleus[i] +v_shift[i], accuracies[i]+val if i %2 == 0 else accuracies[i]-val, name,\n",
    "             ha='left', va=position[i])\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(\"Accuracies vs BLEU scores for the different translators\")\n",
    "plt.xlabel(\"BLEU score\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
